{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b06363",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'defaultdict' from 'collection' (d:\\Exercicios de linguagem natural\\.venv\\Lib\\site-packages\\collection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfuncoes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ler\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#conhecer a quantidade de palavras e vocabulário \u001b[39;00m\n\u001b[32m      4\u001b[39m vocabulario  = ler(palavras)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Exercicios de linguagem natural\\funcoes.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuscador\u001b[39m (alvo,texto):\n\u001b[32m      4\u001b[39m     texto = texto.replace(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'defaultdict' from 'collection' (d:\\Exercicios de linguagem natural\\.venv\\Lib\\site-packages\\collection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from funcoes import ler\n",
    "\n",
    "#conhecer a quantidade de palavras e vocabulário \n",
    "vocabulario  = ler(palavras)\n",
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a7710f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'palavras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Conhecer a quantidade de palavaras e vocabulário \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vocabulario = \u001b[38;5;28mset\u001b[39m(\u001b[43mpalavras\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocabulario)\n",
      "\u001b[31mNameError\u001b[39m: name 'palavras' is not defined"
     ]
    }
   ],
   "source": [
    "#Conhecer a quantidade de palavaras e vocabulário \n",
    "vocabulario = set(palavras)\n",
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calcular a riqueza do corpus \n",
    "riqueza = len(vocabulario)/len(palavras)\n",
    "riqueza "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb2a08",
   "metadata": {},
   "source": [
    "#Criar um dicionário desse texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collection import defaultdict\n",
    "def ocorrencias(lista_palavras):\n",
    "\tdicionario = defaultdict(int)\n",
    "\tfor p in lista_palavras:\n",
    "\t\tdicionario[p] += 1\n",
    "\treturn dicionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = ocorrencias(palavras)\n",
    "mf = sorted(dic.items, key=lambda tupla:tupla[1], reverse=True)[:20]\n",
    "for palavra, n in mf :\n",
    "\tprint(palavra,'t',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae580dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic\n",
    "tupla([0],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "vazias = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d68567",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequentes_plenas = [x for x in mf if x[0].lower() not in vazias]\n",
    "frequentes_plenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31982c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8859231",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "\t#banco de dados para utilização de sinonimos \n",
    "nltk.download('omw-1.4')\n",
    "\t#corpus que relaciona as palavras em diversos idiomas \n",
    "sinonimos = wordnet.synsets(\"carro\", lang\"por\")\n",
    "print(sinonimos) #imprime a lista gerada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sinonimos:\n",
    "\tprint(s.lemas()[0].name()) #mostra sinonimos da palavra\n",
    "\t# s.lemmas(): obtém a lista de lemmas (formas básicas das palavras \n",
    "\t# [0]: pega o primeiro lemmas da lista \n",
    "\t# .name(): obtém o nome do lemma (o sinônimo de si)\n",
    "\t# print(): imprime o sinônimo na tela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183c764",
   "metadata": {},
   "source": [
    "# Representação do significado das palavras e frases por vetores (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da450255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "# carregando o modelo pré treinado - modelo de relações entre as palavras \n",
    "nlp = spacy.load('pt_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criação de objetos , com suas informações e vetores \n",
    "palavra1 = nlp('rei')\n",
    "palavra2 = nlp('rainha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculo de similaridade dos objetos vetorizados \n",
    "print(palavra1.similarity(palavra2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4189445",
   "metadata": {},
   "source": [
    "# Exemplo 4 - Ontologia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "# criando uma nova ontologia \n",
    "onto = get_ontology(\"http://exemplo.com/minha_ontologia.owl\")\n",
    "\n",
    "with onto:\n",
    "\tclass Animal(Thing): pass\n",
    "\tclass Mamifero(Animal): pass\n",
    "\tclass Cachorro(Mamifero): pass\n",
    "\tclass Gato(Mamifero): pass\n",
    "onto.save(\"minha_ontologia.owl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d3273",
   "metadata": {},
   "source": [
    "## Estuso de caso 01 - Aplicação se análise semântica em um corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importanto as bibliotecas necessárias \n",
    "import spacy \n",
    "import nltk \n",
    "import pandas as pd \n",
    "\n",
    "from nltk.corpus import wordnet as wm \n",
    "#banco de dados léxico - agrupas as palvras em grupos de sinônimos \n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#acessar as funcionalidades como tokenização, análise sintática e vetores de palavras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#texto de estudo de caso \n",
    "text = \"apple is looking at ...(completar)\"\n",
    "\n",
    "#análise sintática \n",
    "doc = nlp(text)\n",
    "syntatic_data = []\n",
    "\n",
    "for token in doc:\n",
    "syntatic_data.append({\n",
    "\t\"token\": token.text,\n",
    "\t\"Pos-Tag\": token.pos_,\n",
    "\t\"Dependência\":token.dep_,\n",
    "\t\"Cabeça da Dep\": token.head.text\n",
    "\t})\n",
    "# convertendo em dataframe \n",
    "df_syntatic = pd.DataFrame(syntatic_data)\n",
    "print(\"\\n Análise Sintática:\")\n",
    "print(df_syntatic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconhecimento de entidades nomeadas \n",
    "entities_data = []\n",
    "for ent in doc.ents:\n",
    "\tentities_data.append({\n",
    "\t\t\"Entidade\": ent.text,\n",
    "\t\t\"Tipo\": ent.label_\n",
    "\t})\n",
    "# convertendo para DataFrame\n",
    "df_entities = pd.DataFrame(entities_data)\n",
    "print(\"\\n Reconhecimento de Entidades:\")\n",
    "print(df_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53189cfa",
   "metadata": {},
   "source": [
    "# 3. Análise semântica com wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8461fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_data = []\n",
    "\n",
    "for token in doc:\n",
    "\tsynsets = wm.synsets(token.text)\n",
    "\tif synsets:\n",
    "\t\tsemantic_data.append({\n",
    "\t\t\t\"Palavra\": token.text,\n",
    "\t\t\t\"Significado\": synsets[0].definition()\n",
    "\t\t\t\"Exemplo\": synsets[0].examples()\n",
    "\t\t})\n",
    "\n",
    "#convertendo para DataFrame \n",
    "df_semantic = pd.DataFrame(semantic_data)\n",
    "print(\"\\n Análise Semântica:\")\n",
    "print(df_semantic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
