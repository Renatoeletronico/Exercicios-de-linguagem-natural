{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455c74ad",
   "metadata": {},
   "source": [
    "# Exemplo 01 - NER com Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3112488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon - PER\n",
      "Tesla - ORG\n",
      "Brasil - LOC\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#Carrega o modelo de português\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "#Texto de exemplo \n",
    "texto = \"Elon musk, CEO da Tesla, visitou o Brasil em 2022 para discutir investimentos de 5 bilhões.\"\n",
    "\n",
    "#processa o texto \n",
    "doc = nlp(texto)\n",
    "\n",
    "#imprime as entidades identificadas \n",
    "for entidade in doc.ents:\n",
    "    print(f\"{entidade.text} - {entidade.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18b82b",
   "metadata": {},
   "source": [
    "# Exemplo 02 - NER com NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed94f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\rfs_e\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\rfs_e\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\rfs_e\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\rfs_e\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasil\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "#baixar os pacotes necessários\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "\n",
    "#texto de exemplo \n",
    "texto =\"Barack Obama foi presidente dos Estados Unidos e ganhou o prêmio nobel da paz.\"\n",
    "\n",
    "#tokenização e POS tagging \n",
    "tokens = word_tokenize(texto)\n",
    "tags = pos_tag(tokens)\n",
    "\n",
    "#identificação da entidades \n",
    "entidades = ne_chunk(tags)\n",
    "\n",
    "# exibir as entidades reconhecidas \n",
    "print(entidade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280445a",
   "metadata": {},
   "source": [
    "# Exemplo 03 - Extração de informações com Expressões regulares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69be1071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30 de junho de 2025']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "texto = \"O pagamento deve ser feito até 30 de junho de 2025.\"\n",
    "\n",
    "# Expressão regular para encontrar datas \n",
    "padrao = r\"\\d{1,2} de [a-zA-Z]+ de \\d{4}\"\n",
    "datas = re.findall(padrao, texto)\n",
    "\n",
    "print(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8933305",
   "metadata": {},
   "source": [
    "# Exempo 04 - Extração de informações com regras heurist´cas e dicionários "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7deafc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profissão identificada: engenheiro\n",
      "profissão identificada: médico\n"
     ]
    }
   ],
   "source": [
    "profissoes = [\"engenheiro\",\"cientista de dados\", \"médico\", \"advogado\"]\n",
    "\n",
    "texto = \"O joão e engenheiro de software e trabalha na Tesla e Maoel é médico\"\n",
    "\n",
    "for profissao in profissoes:\n",
    "    if profissao in texto:\n",
    "        print(f\"profissão identificada: {profissao}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da71db7",
   "metadata": {},
   "source": [
    "# Exemplo 05 - Mineração de textos com frequência de palavras e N-gramas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7692c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('de', 2), ('palavras', 2), ('Mineração', 1), ('textos', 1), ('envolve', 1)]\n",
      "[('Mineração', 'de'), ('de', 'textos'), ('textos', 'envolve'), ('envolve', 'análise'), ('análise', 'de'), ('de', 'palavras'), ('palavras', ','), (',', 'palavras'), ('palavras', 'importantes'), ('importantes', 'e'), ('e', 'padrões'), ('padrões', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "texto= \"Mineração de textos envolve análise de palavras, palavras importantes e padrões.\"\n",
    "palavras = nltk.word_tokenize(texto)\n",
    "\n",
    "frequencia = Counter(palavras)\n",
    "print(frequencia.most_common(5)) # top 5 palavras mais frequentes\n",
    "\n",
    "bigrams = list(ngrams(palavras,2))\n",
    "print(bigrams) # bigramas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e13fe",
   "metadata": {},
   "source": [
    "# Exemplo 06 - Mineração de texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd94ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.172*\"artificial\" + 0.167*\"inteligência\" + 0.163*\"aprendzado\" + 0.119*\"dados\" + 0.104*\"estatística\" + 0.101*\"aprendizado\" + 0.089*\"mineração\" + 0.085*\"textos\"'), (1, '0.222*\"dados\" + 0.144*\"textos\" + 0.140*\"mineração\" + 0.131*\"aprendizado\" + 0.128*\"estatística\" + 0.081*\"aprendzado\" + 0.078*\"inteligência\" + 0.074*\"artificial\"')]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "#texto de exemplo \n",
    "documentos = [ [\"mineração\",\"textos\",\"dados\"],\n",
    "[\"inteligência\",\"artificial\",\"aprendzado\"],\n",
    "[\"dados\",\"aprendizado\",\"estatística\"]]\n",
    "\n",
    "#criar dicionário e corpus \n",
    "dicionario = corpora.Dictionary(documentos)\n",
    "corpus = [dicionario.doc2bow(doc) for doc in documentos]\n",
    "\n",
    "#aplicar LDA\n",
    "lda_modelo = models.LdaModel(corpus=corpus, id2word=dicionario, num_topics = 2)\n",
    "print(lda_modelo.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1277cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import machado \n",
    "\n",
    "nltk.download('machado')\n",
    "\n",
    "\n",
    "import zipfile \n",
    "\n",
    "caminho_do_zip = '.......'\n",
    "arquivo_zip = zipfile.ZipFile(caminho_do_zip,'r')\n",
    "arquivo_zip = printdir()\n",
    "\n",
    "#extrair o conteudo para poder analisar \n",
    "import os \n",
    "\n",
    "pasta_destino = '....'\n",
    "os.makedir(pasta_destino, exist_ok = True)\n",
    "arquivo_zip.extractall(pasta_destino)\n",
    "\n",
    "print(f\"Arquivo {caminho_do_zip} extraído com sucesso na pasta {pasta_destino}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433666c2",
   "metadata": {},
   "source": [
    "# Passo 2 - etiquetação morfológica (POS Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_md')\n",
    "\n",
    "doc = nlp(\"Vamos estudar processamento de linguagem natural\")\n",
    "\n",
    "etiq = [(x.orth_,x.pos_) for x in doc]\n",
    "print(etiq)\n",
    "\n",
    "#funcão dos arquivos para serem utilizados \n",
    "from funcoes import ler \n",
    "\n",
    "#obtenção dos caminhos das obras\n",
    "obra = []\n",
    "for i in range(1,6)\n",
    "\tobras.append('....'+ str(1) + '.txt')\n",
    "\n",
    "for i in range(1,6)\n",
    "\tobras.append('....'+ str(1) + '.txt')\n",
    "obras\n",
    "\n",
    "import statistic as stat\n",
    "\n",
    "cont_adv = []\n",
    "\n",
    "for obra in obras:\n",
    "\tprint(obra)\n",
    "\ts = ler(obra)\n",
    "\t\n",
    "\tdoc = nlp(s)\n",
    "\tetiq = [(x.orth_,x.pos_) for x in doc]\n",
    "\tadv = [(ort,pos) for (ort,pos) in etiq if pos == \"ADV\"]\n",
    "\tcont_adv.append(len(adv)/len(etiq))\n",
    "\n",
    "rom_m = stat.mean(cont_adv[:4])\n",
    "rom_dp = stat.stdev(cont_adv[:4])\n",
    "cron_m = stat.mean(cont_adv[5:])\n",
    "nron_dp = stat.stdev(cont_adv[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efb5e8",
   "metadata": {},
   "source": [
    "## Geração do gráfico para demonstração dos resultados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ef838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "tipo_obra = [\"Romance\",\"Cronicas\"]\n",
    "x = [0,1]\n",
    "y = [rom_m,con_m]\n",
    "dp = [rom_dp,cron_dp]\n",
    "\n",
    "plt.bar(x,y,yerr = dp)\n",
    "plt.xticks(x, tipo_obra)\n",
    "plt.ylabel('Percentual médio do advérbio')\n",
    "plt.title('avérbios de obras de mMachado de Assis')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
